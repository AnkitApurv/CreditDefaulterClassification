{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classifier: Final attempt (after internship)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.a. Import: Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#data organizing\n",
    "import pandas #storage\n",
    "import numpy as np #data-type conversion\n",
    "from os import getcwd\n",
    "\n",
    "#preprocessing - data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#outlier removal to achieve better distribution\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "#scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "#classification result - statistical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#model persistence\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b. Import: Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#dtype changed from int64 to int32 to save space and speed up computation, no data was lost\n",
    "\n",
    "url = getcwd() + '\\\\default of credit card clients.xls'\n",
    "ccd = pandas.read_excel(io = url, \\\n",
    "                        sheet_name='Data', header = 1, index_col = 0, \\\n",
    "                        dtype = {'LIMIT_BAL': np.int32, 'AGE': np.int32, 'BILL_AMT1': np.int32, 'BILL_AMT2': np.int32, \\\n",
    "                                 'BILL_AMT3': np.int32, 'BILL_AMT4': np.int32, 'BILL_AMT5': np.int32, 'BILL_AMT6': np.int32, \\\n",
    "                                 'PAY_AMT1': np.int32, 'PAY_AMT2': np.int32, 'PAY_AMT3': np.int32, 'PAY_AMT4': np.int32, \\\n",
    "                                 'PAY_AMT5': np.int32, 'PAY_AMT6': np.int32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ccd.rename(columns = {'PAY_0': 'PAY_1'}, inplace = True)\n",
    "ccd.rename(columns = {'default payment next month': 'default_payment_next_month'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.b. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.b.1. PAY {PAY_1 to PAY_6}\n",
    "\n",
    "1. Using mode to aggregate. An entry may have mutiple mode values (same frequency), to resolve, using severest class.\n",
    "\n",
    "2. Why severest value? To ensure fiscally fit population of credit users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ccdr = pandas.read_excel(io = url, \n",
    "                        sheet_name='Data', header = 1, index_col = 0)\n",
    "ccdr.rename(columns = {'PAY_0': 'PAY_1'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ccdrHistory = ccdr[['PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ccdrHistoryMode = ccdrHistory.mode(axis = 'columns')\n",
    "ccdPayHistoryMode = ccdrHistoryMode.apply(func = max, axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ccd['PAY_MODE_SEVEREST'] = list(ccdPayHistoryMode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.b.2. BILL_AMT {BILL_AMT1 to BILL_AMT6}\n",
    "\n",
    "Using mean for total credit used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ccdSpent = ccd[['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ccd['BILL_AMT_MEAN'] = np.int32(ccdSpent.mean(axis = 'columns').round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.b.3. PAY_AMT {PAY_AMT1 to PAY_AMT6}\n",
    "\n",
    "Using mean for total credit settled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ccdSettled = ccd[['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ccd['PAY_AMT_MEAN'] = np.int32(ccdSettled.mean(axis = 'columns').round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b.4. BALANCE_AMT {PAY_AMT - BILL_AMT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccd['BALANCE_AMT1'] = np.int32(ccd['PAY_AMT1'] - ccd['BILL_AMT1'])\n",
    "ccd['BALANCE_AMT2'] = np.int32(ccd['PAY_AMT2'] - ccd['BILL_AMT2'])\n",
    "ccd['BALANCE_AMT3'] = np.int32(ccd['PAY_AMT3'] - ccd['BILL_AMT3'])\n",
    "ccd['BALANCE_AMT4'] = np.int32(ccd['PAY_AMT4'] - ccd['BILL_AMT4'])\n",
    "ccd['BALANCE_AMT5'] = np.int32(ccd['PAY_AMT5'] - ccd['BILL_AMT5'])\n",
    "ccd['BALANCE_AMT6'] = np.int32(ccd['PAY_AMT6'] - ccd['BILL_AMT6'])\n",
    "\n",
    "ccd['BALANCE_AMT_MEAN'] = np.int32(ccd['PAY_AMT_MEAN'] - ccd['BILL_AMT_MEAN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.c. Normalization\n",
    "\n",
    "Scaling: Only to reduce the effect of very large continuous variables (in distance based esimators).\n",
    "\n",
    "Normalization: Also reduce the effect of skewness in variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "varsToScale = ['LIMIT_BAL', 'AGE', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', \n",
    "               'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'BILL_AMT_MEAN', 'PAY_AMT_MEAN']\n",
    "scaler = StandardScaler(copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in varsToScale:\n",
    "    ccd[var] = scaler.fit_transform(ccd[var].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.a. Removing Outliers\n",
    "\n",
    "Since data is highly skewed with the higher end being very sparse, having mostly outliers,\n",
    "\n",
    "It may be better to remove those outliers so rest of the dataset has better distribution for better prediction\n",
    "And outlier datapoints could be have a separate classifier model\n",
    "\n",
    "Sould be done before data split to ensure distribution of train, dev and test sets are not different from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolationForest = IsolationForest(n_estimators = 100, max_samples = 0.2, contamination = 'auto',\n",
    "                       n_jobs = -1, random_state = 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolationForest.fit(ccd)\n",
    "IsOutlierLabels = isolationForest.predict(ccd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvIsOutlier(prediction):\n",
    "    mapper = {-1: True, 1: False}\n",
    "    return mapper.get(prediction)\n",
    "\n",
    "ccdOutliers = ccd.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccdOutliers['IsOutlier'] = list(map(cvIsOutlier, IsOutlierLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inliers conditions have been selected from EDA observations\n",
    "\n",
    "ccdInliers = ccd[(ccdOutliers['IsOutlier'] == False) & (ccdOutliers['LIMIT_BAL'] <= 525000) & (ccdOutliers['AGE'] <= 60)]\n",
    "ccdOutliers = ccd[~ccd.index.isin(ccdInliers.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.d. Data Splitting\n",
    "\n",
    "Data is split before oversampling to avoid synthetic datapoints in test dataset.\n",
    "\n",
    "Test dataset is separated even though GridSearchCV uses Stratified K-Fold cross-validation so that model's accuracy can be tested independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccdY = pandas.DataFrame(ccdInliers['default_payment_next_month'])\n",
    "ccdX = ccdInliers.drop(['default_payment_next_month'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(ccdX, ccdY, test_size = 0.25, stratify = ccdY, random_state = 44)\n",
    "\n",
    "#devX, testX, devY, testY = train_test_split(testX, testY, test_size = 0.25, stratify = testY, random_state = 44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfRF = RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
    "                               criterion='entropy', max_depth=10, max_features='auto',\n",
    "                               max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0,\n",
    "                               min_impurity_split=None, min_samples_leaf=np.int32(trainX.shape[0]/1000),\n",
    "                               min_samples_split=np.int32(trainX.shape[0]/500),\n",
    "                               min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=-1,\n",
    "                               oob_score=False, random_state=39, verbose=0, warm_start=False)\n",
    "\n",
    "clfLG = LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=1000, multi_class='auto', n_jobs=-1, penalty='none',\n",
    "                   random_state=44, solver='newton-cg', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "\n",
    "clfTrue = GaussianNB(priors=None, var_smoothing=1e-09)\n",
    "\n",
    "clfFalse = SVC(cache_size = 1000, max_iter = -1, random_state = 44, kernel = 'rbf', C = 1.0,\n",
    "               class_weight = 'balanced')\n",
    "\n",
    "classifier = StackingClassifier(estimators = [('clfRF', clfRF), \n",
    "                                              ('clfTrue', clfTrue),\n",
    "                                              ('clfFalse', clfFalse)],\n",
    "                              final_estimator = clfLG,\n",
    "                              n_jobs = -1, passthrough = True, cv = 5, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('clfRF',\n",
       "                                RandomForestClassifier(bootstrap=False,\n",
       "                                                       class_weight='balanced',\n",
       "                                                       criterion='entropy',\n",
       "                                                       max_depth=10,\n",
       "                                                       min_samples_leaf=22,\n",
       "                                                       min_samples_split=44,\n",
       "                                                       n_estimators=250,\n",
       "                                                       n_jobs=-1,\n",
       "                                                       random_state=39)),\n",
       "                               ('clfTrue', GaussianNB()),\n",
       "                               ('clfFalse',\n",
       "                                SVC(cache_size=1000, class_weight='balanced',\n",
       "                                    random_state=44))],\n",
       "                   final_estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                      max_iter=1000, n_jobs=-1,\n",
       "                                                      penalty='none',\n",
       "                                                      random_state=44,\n",
       "                                                      solver='newton-cg'),\n",
       "                   n_jobs=-1, passthrough=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(trainX, trainY.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_classifier.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(classifier, 'best_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredictY = classifier.predict(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredictY = classifier.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.85     17249\n",
      "           1       0.50      0.71      0.59      4820\n",
      "\n",
      "    accuracy                           0.78     22069\n",
      "   macro avg       0.71      0.76      0.72     22069\n",
      "weighted avg       0.82      0.78      0.80     22069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(trainY, trainPredictY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted | Not Defaulter</th>\n",
       "      <th>Defaulter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Correct | Not Defaulter</th>\n",
       "      <td>13910</td>\n",
       "      <td>3339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Defaulter</th>\n",
       "      <td>1415</td>\n",
       "      <td>3405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Predicted | Not Defaulter  Defaulter\n",
       "Correct | Not Defaulter                      13910       3339\n",
       "Defaulter                                     1415       3405"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(\n",
    "    confusion_matrix(trainY, trainPredictY),\n",
    "    columns=['Predicted | Not Defaulter', 'Defaulter'],\n",
    "    index=['Correct | Not Defaulter', 'Defaulter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83      5750\n",
      "           1       0.45      0.64      0.53      1607\n",
      "\n",
      "    accuracy                           0.75      7357\n",
      "   macro avg       0.67      0.71      0.68      7357\n",
      "weighted avg       0.79      0.75      0.76      7357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testY, testPredictY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted | Not Defaulter</th>\n",
       "      <th>Defaulter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Correct | Not Defaulter</th>\n",
       "      <td>4499</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Defaulter</th>\n",
       "      <td>583</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Predicted | Not Defaulter  Defaulter\n",
       "Correct | Not Defaulter                       4499       1251\n",
       "Defaulter                                      583       1024"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(\n",
    "    confusion_matrix(testY, testPredictY),\n",
    "    columns=['Predicted | Not Defaulter', 'Defaulter'],\n",
    "    index=['Correct | Not Defaulter', 'Defaulter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: Prediction of outliers using model trained on inliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliersY = pandas.DataFrame(ccdOutliers['default_payment_next_month'])\n",
    "outliersX = ccdOutliers.drop(['default_payment_next_month'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliersPredictY = classifier.predict(outliersX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       365\n",
      "           1       0.69      0.67      0.68       209\n",
      "\n",
      "    accuracy                           0.77       574\n",
      "   macro avg       0.75      0.75      0.75       574\n",
      "weighted avg       0.77      0.77      0.77       574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(outliersY, outliersPredictY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted | Not Defaulter</th>\n",
       "      <th>Defaulter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Correct | Not Defaulter</th>\n",
       "      <td>302</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Defaulter</th>\n",
       "      <td>70</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Predicted | Not Defaulter  Defaulter\n",
       "Correct | Not Defaulter                        302         63\n",
       "Defaulter                                       70        139"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(\n",
    "    confusion_matrix(outliersY, outliersPredictY),\n",
    "    columns=['Predicted | Not Defaulter', 'Defaulter'],\n",
    "    index=['Correct | Not Defaulter', 'Defaulter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final notes:\n",
    "Success, sort of. This model as the 'marco average recall' of 0.71 for test dataset, 0.75 for that of outlier dataset.\n",
    "Neural network classifier created post-internship had 'macro average recall' of 0.59 for test dataset.\n",
    "Final model at the conclusion of the internship had 'macro average recall' of 0.70 for test dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-CreditDefaulterClassification]",
   "language": "python",
   "name": "conda-env-.conda-CreditDefaulterClassification-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
